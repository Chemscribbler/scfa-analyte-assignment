}
#' Title
#'
#' @param peak this is should be a 1 row dataframe
#' @param reftable
#'
#' @return Returns the analyte (as a factor) or an NA value
#' @export
#'
#' @examples
assign_analytes <- function(peaktable, reftable){
left_join(reftable, peaktable, by = c("ColID")) %>%
filter(RTmin < RT, RTmax > RT)
}
assign_analytes(x,y)
x
y
assign_analytes(y,reftable)
data %>% peakassignment:::sample_label() %>% assign_analytes(reftable)
check_nearby_peaks <- function(peaktable, rttable){
for (ColID in unique(rttable$ColID)) {
for (AnalyteID in unique(rttable$Analyte)) {
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = FALSE, -0.01)
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = TRUE, +0.01)
}
}
return(rttable)
}
check_nearby_peaks(y,rttable)
rttable
check_nearby_peaks <- function(peaktable, rttable, comparisontable=NA){
if (is.na(comparisontable)) {
comparisontable <- peaktable
}
for (ColID in unique(rttable$ColID)) {
for (AnalyteID in unique(rttable$Analyte)) {
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = FALSE, -0.02)
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = TRUE, +0.02)
}
}
temp <- assign_analytes(peaktable, rttable)
return(anti_join(comparisontable,temp))
}
check_nearby_peaks(y, rttable)
check_nearby_peaks <- function(peaktable, rttable, comparisontable=NA){
if (is.na(comparisontable)) {
comparisontable <- peaktable
}
for (ColID in unique(rttable$ColID)) {
for (AnalyteID in unique(rttable$Analyte)) {
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = FALSE, -0.1)
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = TRUE, +0.1)
}
}
temp <- assign_analytes(peaktable, rttable)
return(anti_join(comparisontable,temp))
}
check_nearby_peaks(y, rttable)
check_nearby_peaks <- function(peaktable, rttable, comparisontable=NA){
if (is.na(comparisontable)) {
comparisontable <- peaktable
}
for (ColID in unique(rttable$ColID)) {
for (AnalyteID in unique(rttable$Analyte)) {
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = FALSE, -0.05)
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = TRUE, +0.05)
}
}
temp <- assign_analytes(peaktable, rttable)
return(anti_join(comparisontable,temp))
}
check_nearby_peaks(y, rttable)
check_nearby_peaks <- function(peaktable, rttable, comparisontable=NA){
if (is.na(comparisontable)) {
comparisontable <- peaktable
}
for (ColID in unique(rttable$ColID)) {
for (AnalyteID in unique(rttable$Analyte)) {
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = FALSE, -0.03)
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = TRUE, +0.03)
}
}
temp <- assign_analytes(peaktable, rttable)
return(anti_join(comparisontable,temp))
}
check_nearby_peaks(y, rttable)
check_nearby_peaks <- function(peaktable, rttable, comparisontable=NA){
if (is.na(comparisontable)) {
comparisontable <- peaktable
}
for (ColID in unique(rttable$ColID)) {
for (AnalyteID in unique(rttable$Analyte)) {
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = FALSE, -0.02)
rttable <- adjust_rt(rttable, ColID, AnalyteID,adjustMax = TRUE, +0.02)
}
}
temp <- assign_analytes(peaktable, rttable)
return(anti_join(comparisontable,temp))
}
check_nearby_peaks(y, rttable)
check_nearby_peaks(y, rttable,comparisontable = sample_n(y,100))
sample_n(y,100)
check_nearby_peaks(y, rttable,comparisontable = peakassignment:::sample_label(data))
check_nearby_peaks(y, rttable,comparisontable = peakassignment:::sample_label(data)) %>% filter(SID != "Blank")
data %>% peakassignment:::sample_label() %>% check_nearby_peaks(rttable = rttable)
data %>% peakassignment:::sample_label() %>% check_nearby_peaks(rttable = rttable) %>% filter(SID != "Blank")
data %>% peakassignment:::sample_label() %>% check_nearby_peaks(rttable = rttable, comparisontable = y) %>% filter(SID != "Blank")
y
test_assigned
data %>% peakassignment:::sample_label()
data %>% peakassignment:::sample_label() %>% peakassignment:::generate_retention_table()
generate_rt_table <- function(df, RTwindow=0.022,
analytelist=c("AA","PA","BA","IS"),
excludedpoints=NA, areacutoff=40,
frontrtcutoff=2.2, rearrtcutoff=2.0){
df %>% sample_label() %>%
find_median_rt(analytelist = analytelist, excludedpoints = excludedpoints,
areacutoff = areacutoff, frontrtcutoff = frontrtcutoff,
rearrtcutoff = rearrtcutoff) %>%
create_min_max_rt(window = RTwindow)
}
generate_rt_table(data)
library(peakassignment)
generate_rt_table(data)
generate_rt_table <- function(df, RTwindow=0.022,
analytelist=c("AA","PA","BA","IS"),
excludedpoints=NA, areacutoff=40,
frontrtcutoff=2.2, rearrtcutoff=2.0){
df %>% peakassignment:::sample_label() %>%
find_median_rt(analytelist = analytelist, excludedpoints = excludedpoints,
areacutoff = areacutoff, frontrtcutoff = frontrtcutoff,
rearrtcutoff = rearrtcutoff) %>%
create_min_max_rt(window = RTwindow)
}
generate_rt_table(data)
install("peakassignment")
rm(adjust_rt())
rm(adjust_rt)
rm(assign_analytes)
rm(check_rt_table)
rm(generate_rt_table)
library(peakassignment)
library(tidyverse)
library(peakassignment)
data <- read_csv(file = "C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190820-Red/data.csv") %>% peakassignment:::sample_label()
data %>% generate_rt_table()
data %>% find_median_rt()
library(devtools)
install("peakassignment")
setwd("..")
install("peakassignment")
uninstall("peakassignment")
install("peakassignment")
library(peakassignment)
find_median_rt(data)
find_median_rt(data,rearrtcutoff = 1.8)
document()
setwd("./peakassignment/")
document()
document()
document()
setwd("..")
install("peakassignment")
library(peakassignment)
library(tidyverse)
library(devtools)
library(roxygen2)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(tidyverse)
library(broom)
library(stringr)
#Data is in a wide format (every peak in an injection on the same row), want to convert it to one peak/row
WidetoTall <- function(DF) {
DF %>%
#Removing unneccessary/blank columns in the original sheet
select(SampleID,ColID,SampleMTime,starts_with("AR"),starts_with("RT")) %>%
#Gather is a tidyverse function that combine columns
gather(starts_with("AR"),key = "ARPeakNumber",value = "Area") %>%
gather(starts_with("RT"),key = "RTPeakNumber",value = "RT") %>%
#This is just to get the original peak number (so the first peak in each specta is 1, second is 2, etc)
mutate(
ARPeakNumber = as.numeric(substr(ARPeakNumber,4,5)),
RTPeakNumber = as.numeric(substr(RTPeakNumber,4,5))
) %>%
#Because of how gather works, need to remove mismatched peaks
filter(ARPeakNumber == RTPeakNumber) %>%
transmute(
SampleID = SampleID,
SampleMTime = SampleMTime,
ColID = ColID,
InitialPeakNum = ARPeakNumber,
Area = Area,
RT = RT
)}
#Separates the SampleID into its component subgroups to make data easier to wrangle
divSID <- function(DF){
DF %>%
separate(col = SampleID,into = c("Exp","Plate","Well"),extra = "merge",fill = "right") %>%
separate(col = ColID, into = c("Misc","ColID"),sep = "=") %>%
filter(ColID != "Blank") %>%
mutate(ColID = as.numeric(ColID),
SampleType = if_else(grepl("c",Plate),
"Calibration",
if_else(grepl("[A,C,M,T][Q,M,N,W]",Well),"Control","Sample")),
CurveID = if_else(grepl("Cal",SampleType),as.numeric(substr(Plate,2,3)),NaN),
PlateID = if_else(!grepl("Calibration",SampleType),as.numeric(substr(Plate,2,3)),NaN),
ControlNum = if_else(grepl("Con",SampleType),as.numeric(substr(Well,4,5)),NaN))
}
#A wrapper function
RawtoTallDiv <- function(DF){
DF %>% WidetoTall(.) %>% divSID(.)
}
#Used for establishing the factor levels
scfa_levels <- c("AA","FA","PA","IsoBA","BA","IsoVA","VA","IS","IsoCA","CA","HA")
#called later down
#Correlates elution order with sample identity
PeaktoCompound <- tibble(PeakNumber = 1:10,
Analyte = factor(c("AA","FA","PA","IsoBA","BA","IsoVA","VA","IsoCA","CA","HA")))
PeaktoCompound_NoFA <- tibble(PeakNumber = 1:9,
Analyte = factor(c("AA","PA","IsoBA","BA","IsoVA","VA","IsoCA","CA","HA")))
PeaktoCompound_IS <- tibble(PeakNumber = 1:10,
Analyte = factor(c("AA","PA","IsoBA","BA","IsoVA","VA","IS","IsoCA","CA","HA")))
PeaktoCompound_ISFA <- tibble(PeakNumber = 1:11,
Analyte = factor(c("AA","FA","PA","IsoBA","BA","IsoVA","VA","IS","IsoCA","CA","HA")))
PeaktoCompound_ShortList <- tibble(PeakNumber = 1:3,
Analyte = factor(c("AA","PA","BA")))
PeaktoCompound_ShortList_IS <- tibble(PeakNumber = 1:4,
Analyte = factor(c("AA","PA","BA","IS")))
PeaktoCompound_ShortList_ISFA <- tibble(PeakNumber = 1:6,
Analyte = factor(c("AA","FA","PA","IsoBA","BA","IS")))
data <- read_csv(file = "C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190821-Blue/data.csv")
reformated_data <- data %>%
separate(col = SID,into = c("Exp","Plate","Well"),extra = "merge",fill = "right") %>%
mutate(ColID = as.numeric(substr(ColID, 10, 11)),
SampleType = if_else(grepl("c",Plate),
"Calibration",
if_else(grepl("[A,C,M,T][Q,M,N,W]",Well),"Control","Sample")),
CurveID = if_else(grepl("Cal",SampleType),as.numeric(substr(Plate,2,3)),NaN),
PlateID = if_else(!grepl("Calibration",SampleType),as.numeric(substr(Plate,2,3)),NaN),
ControlNum = if_else(grepl("Con",SampleType),as.numeric(substr(Well,4,5)),NaN))
#Make a reference table for each column
#Reference table is make by taking the controls and doing some filtering for low/extraneous peaks
front_reftable <- reformated_data %>% filter(SampleType == "Control", grepl("CM",Well),grepl("G",Exp),!is.na(RT),
!(ColID %% 2 == 0 & RT < 2.2),Area > 40, ColID %% 2 == 0) %>%
group_by(ControlNum,PlateID) %>%
slice(1:11) %>%
mutate(PeakNumber = row_number()) %>%
left_join(y = PeaktoCompound_ShortList_IS) %>%
ungroup%>%
group_by(ColID,Analyte) %>%
summarise(RTmed = median(RT)) %>%
mutate(
RTmin = RTmed - 0.022,
RTmax = RTmed + 0.02,
RTmax =if_else(Analyte == "BA", RTmax + 0.005,RTmax)
) %>%
select(ColID,Analyte, RTmin, RTmax)
rear_reftable<- reformated_data %>% filter(SampleType == "Control",!is.na(RT),
!(ColID %% 2 == 1 & RT < 1),Area > 40, ColID %% 2 == 1) %>%
group_by(ControlNum,PlateID) %>%
slice(1:11) %>%
mutate(PeakNumber = row_number()) %>%
left_join(y = PeaktoCompound_ShortList_IS) %>%
ungroup%>%
group_by(ColID,Analyte) %>%
summarise(RTmed = median(RT)) %>%
mutate(
RTmin = RTmed - 0.01,
RTmax = RTmed + 0.02,
RTmin = if_else(Analyte == "AA"|Analyte == "PA",RTmin - 0.03, RTmin),
RTmax = if_else(Analyte == "AA"|Analyte == "PA",RTmax + 0.04, RTmax),
RTmin = if_else(Analyte == "AA",RTmin - 0.02, RTmin),
RTmax = if_else(Analyte == "AA",RTmax + 0.01, RTmax),
Analyte = factor(Analyte, levels = scfa_levels)) %>%
arrange(Analyte) %>%
select(ColID,Analyte, RTmin, RTmax)
reftable <- bind_rows(front_reftable,rear_reftable) %>% filter(!is.na(RTmin),!is.na(Analyte))
#This function does not really get called on its own, typically only called by AssignAnalytes
#This function is just a for loop, but when I run it as a for loop it takes ~10x times longer
analyteAssignment <- function(inputRT,refRTtable,inputColID){
#I had a lot of data formatting/extraction issues, so there is a lot of type forcing going on
inputRT <- as.double(unlist(inputRT))
refRTtable <- refRTtable %>% filter(as.double(unlist(ColID)) == as.double(unlist(inputColID)))
for(i in 1:nrow(refRTtable)){
if(between(inputRT, (as.double(refRTtable[i,3])),(as.double(refRTtable[i,4])))){
return(as.character(unlist(refRTtable[i,2])))
}
}
return(NA)
}
AssignAnalytes <- function(DF,ExcludedCurves = NA,PeaktoCompoundMap = PeaktoCompound, DefRefTable = NA){
#This is just because I need to pass ColID into the analyte assignment function
ColList <- DF %>% distinct(ColID) %>% as.list(.)
refRTtable <- DefRefTable
#A reference RT table can abe provided, but that typically only happens after this call mis-assigns
if(is.na(refRTtable)){
refRTtable <-  DF %>% makeRTRefTable(ExcludedCurves = ExcludedCurves,PeaktoCompoundMap)}
ParsedDF <- tibble()
for(x in ColList[[1]]){
ParsedDF <- DF %>% filter(!is.na(RT), ColID == x)%>%
mutate(Analyte = map_chr(RT, function(y) as.character(analyteAssignment(y,refRTtable,x)))) %>%
select(-PeakNum) %>% bind_rows(ParsedDF,.)
}
#This is just done to make the data present in an order that makes sense
ParsedDF <- ParsedDF %>% mutate(Analyte = factor(Analyte, levels = scfa_levels))
return(ParsedDF)
}
assigned_data <- reformated_data %>%
AssignAnalytes(DefRefTable = reftable)
#Plot of assigned data
assigned_data %>%
filter(grepl("[A,G]",Exp)) %>%
ggplot(mapping = aes(x = RT, y = Area, color = Analyte, shape = SampleType))+geom_point()+facet_wrap(~ColID)+
coord_cartesian(xlim = c(1,4), ylim = c(-.5,2500))
compressed_assigned_data <- assigned_data %>%
filter(!is.na(Analyte)) %>%
group_by(InjTime, Analyte, Exp, Plate, Well, PlateID, CurveID, ColID, SampleType, ControlNum) %>%
summarise(
Area = sum(Area),
RT = mean(RT),
)
compressed_assigned_data %>%
distinct(Exp,ColID,PlateID)
compressed_assigned_data %>% filter(SampleType == "Calibration", Analyte != "FA", Analyte != "IS", Area > 5) %>%
mutate(Conc = as.numeric(substr(Well,2,4))) %>%
ggplot(mapping = aes(x = (Conc), y = (Area), color = as.factor(CurveID)))+geom_point()+geom_smooth(method = "lm")+
facet_grid(ColID~Analyte, scales = "free")+coord_cartesian(xlim = c(0,60),ylim = c(-10,1400))
#Making a calibration curve, in this case I filter for a specific curve (CurveID %in% (x)) in csae multiple curves are loaded.
curvedata <- compressed_assigned_data %>%
filter(CurveID %in% c(16),grepl("M",substr(Well,1,1)), Area > 5) %>%
#Concentrations are stored in sampleIDs, so I'm extracting that information
mutate(
Conc = as.numeric(substr(Well,2,10))
) %>%
filter(!is.na(Analyte)) %>%
group_by(CurveID,ColID,Analyte) %>%
nest() %>%
#in analytical chemistry convention this should be Area ~ Concentration, but when I've done it that way it breaks the code
mutate(fit = map(data, ~lm(Conc ~ Area, data = ., weights = 1/(Conc)^2))) %>%
select(-data)
#This is a just a data quality check
curvedata %>%
mutate(stats = map(fit,tidy)) %>%
unnest(stats) %>%
filter(term == "Area", Analyte %in% c("AA","PA","BA")) %>%
mutate(Slope = 1/estimate)
#Making a calibration curve, in this case I filter for a specific curve (CurveID %in% (x)) in csae multiple curves are loaded.
curvedata <- compressed_assigned_data %>%
filter(CurveID %in% c(18),grepl("M",substr(Well,1,1)), Area > 5) %>%
#Concentrations are stored in sampleIDs, so I'm extracting that information
mutate(
Conc = as.numeric(substr(Well,2,10))
) %>%
filter(!is.na(Analyte)) %>%
group_by(CurveID,ColID,Analyte) %>%
nest() %>%
#in analytical chemistry convention this should be Area ~ Concentration, but when I've done it that way it breaks the code
mutate(fit = map(data, ~lm(Conc ~ Area, data = ., weights = 1/(Conc)^2))) %>%
select(-data)
compressed_assigned_data %>% filter(SampleType == "Calibration", Analyte != "FA", Analyte != "IS", Area > 5) %>%
mutate(Conc = as.numeric(substr(Well,2,4))) %>%
ggplot(mapping = aes(x = (Conc), y = (Area), color = as.factor(CurveID)))+geom_point()+geom_smooth(method = "lm")+
facet_grid(ColID~Analyte, scales = "free")+coord_cartesian(xlim = c(0,60),ylim = c(-10,1400))
#Making a calibration curve, in this case I filter for a specific curve (CurveID %in% (x)) in csae multiple curves are loaded.
curvedata <- compressed_assigned_data %>%
filter(CurveID %in% c(18),grepl("M",substr(Well,1,1)), Area > 5) %>%
#Concentrations are stored in sampleIDs, so I'm extracting that information
mutate(
Conc = as.numeric(substr(Well,2,10))
) %>%
filter(!is.na(Analyte)) %>%
group_by(CurveID,ColID,Analyte) %>%
nest() %>%
#in analytical chemistry convention this should be Area ~ Concentration, but when I've done it that way it breaks the code
mutate(fit = map(data, ~lm(Conc ~ Area, data = ., weights = 1/(Conc)^2))) %>%
select(-data)
#This is a just a data quality check
curvedata %>%
mutate(stats = map(fit,tidy)) %>%
unnest(stats) %>%
filter(term == "Area", Analyte %in% c("AA","PA","BA")) %>%
mutate(Slope = 1/estimate)
#More quality checks
curvedata %>%
mutate(stats = map(fit,glance)) %>%
unnest(stats) %>%
filter(Analyte %in% c("AA","PA","BA"))
#This is applying the curve to the analytes
calc_data <- compressed_assigned_data %>% group_by(ColID, Exp,PlateID,Analyte) %>%
nest() %>%
inner_join(y = curvedata, by = c("ColID","Analyte")) %>%
mutate(NoCurve = sapply(fit, is.null)) %>%
filter(!is.nan(PlateID),!is.na(Analyte),!NoCurve) %>%
mutate(Conc.mM = map2(fit,data,predict.lm)) %>%
unnest(Conc.mM,data) %>%
mutate(Analyte = factor(Analyte,levels = scfa_levels))
calc_data %>%
filter(SampleType == "Control", Analyte != "FA", grepl("CM",Well),grepl("G",Exp)) %>%
filter() %>%
group_by(Exp,PlateID,ColID,Analyte) %>%
summarise(MeanConc = mean(Conc.mM),
CVConc = sd(Conc.mM)/MeanConc*100,
PercRecov = MeanConc/10*100,
#PercError = abs(10-MeanConc)/10*100,
MeanArea = mean(Area),
Count = n()) %>%
mutate_if(is.double,funs(round(.,1))) %>%
print(n = Inf)
#write_csv(path = "C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190626-Blue/10mM_controls.csv")
calc_data %>%
filter(SampleType == "Control", Analyte != "FA", grepl("CM",Well),grepl("G",Exp)) %>%
filter(Analyte != "IS") %>%
group_by(Exp,PlateID,ColID,Analyte) %>%
ggplot(mapping = aes(x = ControlNum, y = Conc.mM, color = as.factor(PlateID)))+geom_point()+facet_grid(Analyte~ColID)
calc_data %>%
mutate(Conc.mM = Conc.mM,
PlateRow = substr(Well,1,1), PlateCol = substr(Well,2,3),
PlateRow = factor(PlateRow, levels = rev(levels(factor(PlateRow))))) %>%
filter(PlateCol != 12, Analyte == "IS") %>%
ggplot(mapping = aes(y = PlateRow, x = as.integer(PlateCol)))+geom_raster(aes(fill = Area))+
facet_grid(Analyte~PlateID)
calc_data %>%
mutate(Conc.mM = Conc.mM,
PlateRow = substr(Well,1,1), PlateCol = substr(Well,2,3),
PlateRow = factor(PlateRow, levels = rev(levels(factor(PlateRow))))) %>%
filter(PlateCol != 12, Analyte != "FA") %>%
ggplot(mapping = aes(y = PlateRow, x = as.integer(PlateCol)))+geom_raster(aes(fill = Conc.mM))+
facet_grid(Analyte~PlateID)
calc_data %>%
#Cleaning Data
filter(SampleType == "Sample",Exp != "Blank",Conc.mM >1) %>%
#Removing Individual Points
filter() %>%
transmute(
ColID = ColID,
Exp = Exp,
PlateID = PlateID,
Analyte = Analyte,
Row = substr(Well,1,1),
Column = as.numeric(substr(Well,2,3)),
PlateSide = if_else(Row %in% c("B","C","D"),"BCD","EFG"),
Conc.mM = Conc.mM,
Area = Area
) %>%
group_by(
Exp,PlateID,PlateSide,Column,Analyte
) %>%
summarise(
MeanArea = mean(Area),
CVArea = sd(Area)/MeanArea*100,
MeanConc = mean(Conc.mM),
CVConc = sd(Conc.mM)/MeanConc*100,
N = n()
) %>%
filter(CVArea > 15)
calc_data %>%
unite(SampleID,Exp, Plate, Well, sep = ".") %>%
select(ColID, SampleID, Analyte, Conc.mM, Area, RT) %>%
write_csv("C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190821-Blue/G779p18p19.csv")
read_csv("C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190821-Blue/G779p18p19.csv") %>%
filter(!(Analyte %in% "FA"),grepl("G",SampleID)) %>%
filter(Conc.mM >0) %>%
filter(
!grepl("p19.B2",SampleID), #Overdiluted
!grepl("p19.B3",SampleID), #High IS peak
!grepl("p19.G11",SampleID), #Overdiluted
) %>%
select(ColID, SampleID, Analyte, Conc.mM, Area, RT) %>%
write_csv("C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190821-Blue/G779p18p19cleaned.csv")
read_csv("C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190821-Blue/G779p18p19cleaned.csv") %>%
filter(Analyte != "IsoBA") %>%
filter(Conc.mM >0) %>%
select(ColID, SampleID, Analyte, Conc.mM, Area, RT) %>%
write_csv("C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190821-Blue/G779p18p19final.csv")
dr_devtools()
devtools::load_all(".")
check_nearby_peaks()
rm(list = ls())
check_nearby_peaks()
data <- read_csv("C:/Users/jpruyne/Documents/Raw_SCFA_Data/20190821-Blue/data.csv")
generate_rt_table(data)
data %>% sample_label()
data %>% sample_label() %>% find_median_rt()
data %>% sample_label() %>% find_median_rt() %>% create_min_max_rt()
devtools::load_all(".")
data %>% sample_label() %>% find_median_rt() %>% create_min_max_rt()
devtools::load_all(".")
data %>% sample_label() %>% find_median_rt() %>% create_min_max_rt()
data %>% generate_rt_table()
devtools::load_all(".")
data %>% generate_rt_table()
rt_table <- data %>% generate_rt_table()
assign_analytes(data, rt_table)
data %>% sample_label()
data
devtools::load_all(".")
assign_analytes(data,rt_table)
assign_analytes(sample_label(data),rt_table)
devtools::load_all(".")
assign_analytes(data,rt_table)
devtools::load_all(".")
help(load_all)
help(load_all)
check_nearby_peaks(data)
devtools::load_all(".")
check_nearby_peaks(data)
data %>% generate_rt_table()
devtools::load_all(".")
data %>% generate_rt_table()
check_nearby_peaks(data)
devtools::load_all(".")
document()
